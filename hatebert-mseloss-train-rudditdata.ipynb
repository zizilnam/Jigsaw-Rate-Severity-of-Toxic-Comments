{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport re\nimport time\nimport random\nimport string\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm\nfrom collections import defaultdict\nimport copy\nfrom copy import deepcopy\n\nimport nltk\n# from nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom transformers import AutoTokenizer, AutoModel, AdamW\n\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-09T14:58:19.088634Z","iopub.execute_input":"2021-12-09T14:58:19.089365Z","iopub.status.idle":"2021-12-09T14:58:26.713133Z","shell.execute_reply.started":"2021-12-09T14:58:19.089266Z","shell.execute_reply":"2021-12-09T14:58:26.712401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# id_generator","metadata":{}},{"cell_type":"code","source":"def id_generator(size = 12, chars = string.ascii_lowercase + string.digits):\n    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n\nHASH_NAME = id_generator(size = 12)\nprint(HASH_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:26.71473Z","iopub.execute_input":"2021-12-09T14:58:26.714981Z","iopub.status.idle":"2021-12-09T14:58:26.723392Z","shell.execute_reply.started":"2021-12-09T14:58:26.714929Z","shell.execute_reply":"2021-12-09T14:58:26.722616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"CONFIG = {\"seed\": 2021,\n          \"epochs\": 10,\n          \"model_name\": \"GroNLP/hateBERT\",\n#           \"model_name\": \"roberta-base\",\n          \"train_batch_size\": 32,\n          \"valid_batch_size\": 64,\n          \"max_length\": 128,\n          \"learning_rate\": 1e-4,\n          \"scheduler\": 'CosineAnnealingLR',\n          \"min_lr\": 1e-6,\n          \"T_max\": 500,\n          \"weight_decay\": 1e-6,\n          \"n_fold\": 5,\n          \"n_accumulate\": 1,\n          \"num_classes\": 1,\n          \"margin\": 0.5,\n          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n          \"hash_name\": HASH_NAME\n          }\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nCONFIG['group'] = f'{HASH_NAME}-Baseline'","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:26.724756Z","iopub.execute_input":"2021-12-09T14:58:26.725161Z","iopub.status.idle":"2021-12-09T14:58:30.630228Z","shell.execute_reply.started":"2021-12-09T14:58:26.725124Z","shell.execute_reply":"2021-12-09T14:58:30.629414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deteministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.632611Z","iopub.execute_input":"2021-12-09T14:58:30.632976Z","iopub.status.idle":"2021-12-09T14:58:30.642655Z","shell.execute_reply.started":"2021-12-09T14:58:30.632922Z","shell.execute_reply":"2021-12-09T14:58:30.641866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')\nprint(df.shape)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.644518Z","iopub.execute_input":"2021-12-09T14:58:30.6452Z","iopub.status.idle":"2021-12-09T14:58:30.743137Z","shell.execute_reply.started":"2021-12-09T14:58:30.645162Z","shell.execute_reply":"2021-12-09T14:58:30.742438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Give more weight to severe toxic \n# df['severe_toxic'] = df.severe_toxic * 10\n# df['toxic'] = df.toxic * 6 \n# df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\n# df['y'] = df['y']/df['y'].max()\n\n# df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n# df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.744606Z","iopub.execute_input":"2021-12-09T14:58:30.745079Z","iopub.status.idle":"2021-12-09T14:58:30.749923Z","shell.execute_reply.started":"2021-12-09T14:58:30.745042Z","shell.execute_reply":"2021-12-09T14:58:30.749043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\ndf = df[['txt', 'offensiveness_score']]\ndf.columns = ['text', 'score']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.751281Z","iopub.execute_input":"2021-12-09T14:58:30.751641Z","iopub.status.idle":"2021-12-09T14:58:30.774045Z","shell.execute_reply.started":"2021-12-09T14:58:30.751589Z","shell.execute_reply":"2021-12-09T14:58:30.773285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.score.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.77518Z","iopub.execute_input":"2021-12-09T14:58:30.77555Z","iopub.status.idle":"2021-12-09T14:58:30.787216Z","shell.execute_reply.started":"2021-12-09T14:58:30.775513Z","shell.execute_reply":"2021-12-09T14:58:30.786415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n\n# df1 = pd.read_csv('../input/ruddit-jigsaw-dataset-combined-cleaned/toxic_train.csv')\n# df1 = df1[['txt', 'offensiveness_score']]\n# df1.columns = ['text', 'score']\n# print(df1.shape)\n# df1.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.788526Z","iopub.execute_input":"2021-12-09T14:58:30.789282Z","iopub.status.idle":"2021-12-09T14:58:30.795917Z","shell.execute_reply.started":"2021-12-09T14:58:30.789241Z","shell.execute_reply":"2021-12-09T14:58:30.79507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from copy import deepcopy\n# print(df1.loc[df1.score!=0.0].shape)\n# df2 = deepcopy(df1.loc[df1.score!=0.0])\n# df2.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.800439Z","iopub.execute_input":"2021-12-09T14:58:30.801259Z","iopub.status.idle":"2021-12-09T14:58:30.805765Z","shell.execute_reply.started":"2021-12-09T14:58:30.801216Z","shell.execute_reply":"2021-12-09T14:58:30.805016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from copy import deepcopy\n# df3 = deepcopy(df1.loc[df1.score == 0])\n# print(df3.shape)\n# df3.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.807118Z","iopub.execute_input":"2021-12-09T14:58:30.807633Z","iopub.status.idle":"2021-12-09T14:58:30.813799Z","shell.execute_reply.started":"2021-12-09T14:58:30.807582Z","shell.execute_reply":"2021-12-09T14:58:30.812976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.concat([df, df2],axis = 0)\n# df = df.reset_index(drop=True)\n# print(df.shape)\n# df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.815129Z","iopub.execute_input":"2021-12-09T14:58:30.815479Z","iopub.status.idle":"2021-12-09T14:58:30.82278Z","shell.execute_reply.started":"2021-12-09T14:58:30.815441Z","shell.execute_reply":"2021-12-09T14:58:30.82198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# nltk.download('stopwords')\n# STOPWORDS = nltk.corpus.stopwords.words('english')\n\n# ## kesha_mandal's code\n# def washing(comment):\n\n#     comment = re.sub('[^a-zA-Z]', ' ', comment)\n#     comment = comment.lower()\n#     comment = comment.split()\n#     stemmer = SnowballStemmer('english')\n#     lemmatizer = WordNetLemmatizer()\n#     comment = [stemmer.stem(word) for word in comment if not word in set(STOPWORDS)]\n#     comment = [lemmatizer.lemmatize(word) for word in comment]\n#     comment = ' '.join(comment)\n#     # corpus.append(comment)\n#     # return corpus\n#     return comment\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.824327Z","iopub.execute_input":"2021-12-09T14:58:30.824623Z","iopub.status.idle":"2021-12-09T14:58:30.832297Z","shell.execute_reply.started":"2021-12-09T14:58:30.824586Z","shell.execute_reply":"2021-12-09T14:58:30.831496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##  https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-infer/notebook\n# def text_cleaning(text):\n    \n#     template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n#     text = template.sub(r'', text)\n    \n#     soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n#     only_text = soup.get_text()\n#     text = only_text\n    \n#     emoji_pattern = re.compile(\"[\"\n#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n#                                u\"\\U00002702-\\U000027B0\"\n#                                u\"\\U000024C2-\\U0001F251\"\n#                                \"]+\", flags=re.UNICODE)\n#     text = emoji_pattern.sub(r'', text)\n    \n#     text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n#     text = re.sub(' +', ' ', text) #Remove Extra Spaces\n#     text = text.strip() # remove spaces at the beginning and at the end of string\n\n#     return text","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.833545Z","iopub.execute_input":"2021-12-09T14:58:30.834001Z","iopub.status.idle":"2021-12-09T14:58:30.844237Z","shell.execute_reply.started":"2021-12-09T14:58:30.833965Z","shell.execute_reply":"2021-12-09T14:58:30.843384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## https://www.kaggle.com/kishalmandal/most-detailed-eda-tf-idf-and-logistic-reg\n\n# df[\"less_toxic\"] = df[\"less_toxic\"].str.replace('fk', 'fuck')\n# df[\"less_toxic\"] = df[\"less_toxic\"].str.replace('fuk', 'fuck')\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.84662Z","iopub.execute_input":"2021-12-09T14:58:30.847212Z","iopub.status.idle":"2021-12-09T14:58:30.853042Z","shell.execute_reply.started":"2021-12-09T14:58:30.847173Z","shell.execute_reply":"2021-12-09T14:58:30.85214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['less_toxic'] = df['less_toxic'].apply(text_cleaning)\n# df['more_toxic'] = df['more_toxic'].apply(text_cleaning)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.854889Z","iopub.execute_input":"2021-12-09T14:58:30.85569Z","iopub.status.idle":"2021-12-09T14:58:30.861976Z","shell.execute_reply.started":"2021-12-09T14:58:30.855605Z","shell.execute_reply":"2021-12-09T14:58:30.861015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['less_toxic'] = df['less_toxic'].apply(washing)\n# df['more_toxic'] = df['more_toxic'].apply(washing)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.863468Z","iopub.execute_input":"2021-12-09T14:58:30.863723Z","iopub.status.idle":"2021-12-09T14:58:30.872551Z","shell.execute_reply.started":"2021-12-09T14:58:30.863686Z","shell.execute_reply":"2021-12-09T14:58:30.87165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFold","metadata":{}},{"cell_type":"code","source":"k = CONFIG['n_fold']\nskf = KFold(n_splits = k, shuffle = True, random_state = CONFIG['seed'])\nfor fold, (k, v) in enumerate(skf.split(X = df)):\n    df.loc[v, 'kfold'] = int(fold)\n\ndf['kfold'] = df['kfold'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.875056Z","iopub.execute_input":"2021-12-09T14:58:30.875585Z","iopub.status.idle":"2021-12-09T14:58:30.896334Z","shell.execute_reply.started":"2021-12-09T14:58:30.875548Z","shell.execute_reply":"2021-12-09T14:58:30.895648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class JDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        \n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        self.score = df['score']\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(text, truncation = True,\n                                            add_special_tokens = True, \n                                            max_length = self.max_len,\n                                            padding = 'max_length')\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        target = self.score[index]\n        \n        return {'ids' : torch.tensor(ids, dtype = torch.long), \n                'mask' : torch.tensor(mask, dtype = torch.long),\n                'target' : torch.tensor(target, dtype = torch.float)\n               }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.897543Z","iopub.execute_input":"2021-12-09T14:58:30.897876Z","iopub.status.idle":"2021-12-09T14:58:30.907171Z","shell.execute_reply.started":"2021-12-09T14:58:30.897838Z","shell.execute_reply":"2021-12-09T14:58:30.906272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepare_loader Function","metadata":{}},{"cell_type":"code","source":"def prepare_loaders(fold):\n    \n    df_train = df[df.kfold != fold].reset_index(drop = True)\n    df_valid = df[df.kfold == fold].reset_index(drop = True)\n    \n    train_dataset = JDataset(df_train, tokenizer = CONFIG['tokenizer'], max_length = CONFIG['max_length'])\n    valid_dataset = JDataset(df_valid, tokenizer = CONFIG['tokenizer'], max_length = CONFIG['max_length'])\n    \n    train_loader = DataLoader(train_dataset, \n                              batch_size = CONFIG['train_batch_size'],\n                              num_workers = os.cpu_count(),\n                              shuffle = True, \n                              pin_memory = True,\n                              drop_last = True)\n    \n    valid_loader = DataLoader(valid_dataset, \n                              batch_size = CONFIG['train_batch_size'],\n                              num_workers = os.cpu_count(),\n                              shuffle = False,\n                              pin_memory = True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.908808Z","iopub.execute_input":"2021-12-09T14:58:30.909365Z","iopub.status.idle":"2021-12-09T14:58:30.919065Z","shell.execute_reply.started":"2021-12-09T14:58:30.909325Z","shell.execute_reply":"2021-12-09T14:58:30.918215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(p = 0.2)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n#         self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, ids, mask):\n        model_out = self.model(input_ids = ids,\n                               attention_mask = mask,\n                               output_hidden_states = False)\n        \n        out = self.dropout(model_out[1])\n        output = self.linear(out)\n#         outputs = self.sigmoid(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.920402Z","iopub.execute_input":"2021-12-09T14:58:30.920775Z","iopub.status.idle":"2021-12-09T14:58:30.930738Z","shell.execute_reply.started":"2021-12-09T14:58:30.920705Z","shell.execute_reply":"2021-12-09T14:58:30.930016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n# loss_fn = nn.BCELoss()\n# loss_fn= nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.932208Z","iopub.execute_input":"2021-12-09T14:58:30.932522Z","iopub.status.idle":"2021-12-09T14:58:30.939098Z","shell.execute_reply.started":"2021-12-09T14:58:30.932485Z","shell.execute_reply":"2021-12-09T14:58:30.938356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train one Epoch Function","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    \n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.\n    \n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    \n    for step, data in bar:\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        targets = data['target'].to(device, dtype = torch.float)\n        targets= targets.reshape(-1, 1)\n        \n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask)\n        \n        loss = loss_fn(outputs, targets)\n        loss = loss / CONFIG['n_accumulate']\n        loss.backward()\n        \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.940581Z","iopub.execute_input":"2021-12-09T14:58:30.940829Z","iopub.status.idle":"2021-12-09T14:58:30.951667Z","shell.execute_reply.started":"2021-12-09T14:58:30.940797Z","shell.execute_reply":"2021-12-09T14:58:30.95086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    \n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.\n    \n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    \n    for step, data in bar:\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        targets = data['target'].to(device, dtype = torch.float)\n        targets= targets.reshape(-1, 1)\n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask)\n#         outputs\n        loss = loss_fn(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.952937Z","iopub.execute_input":"2021-12-09T14:58:30.953688Z","iopub.status.idle":"2021-12-09T14:58:30.964123Z","shell.execute_reply.started":"2021-12-09T14:58:30.953651Z","shell.execute_reply":"2021-12-09T14:58:30.963301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Training Function","metadata":{}},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n    \n    if torch.cuda.is_available():\n        print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n        print()\n        \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_loss = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader = train_loader, device = CONFIG['device'], epoch = epoch)\n        valid_epoch_loss = valid_one_epoch(model, dataloader = valid_loader, device = CONFIG['device'], epoch = epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        \n        if valid_epoch_loss <= best_epoch_loss:\n            print(f\"{b_} Validation Loss Improved: [{best_epoch_loss} ---> {valid_epoch_loss}]\")\n            best_epoch_loss = valid_epoch_loss\n#             run.summary['Best Loss'] = best_epoch_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f\"Loss-Fold-{fold}.bin\"\n            torch.save(model.state_dict(), PATH)\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n        \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.965471Z","iopub.execute_input":"2021-12-09T14:58:30.965743Z","iopub.status.idle":"2021-12-09T14:58:30.977519Z","shell.execute_reply.started":"2021-12-09T14:58:30.965709Z","shell.execute_reply":"2021-12-09T14:58:30.97675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fetch_scheduler function","metadata":{}},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, \n                                                   T_max = CONFIG['T_max'],\n                                                   eta_min = CONFIG['min_lr'])\n        \n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n                                                             T_0 = CONFIG['T_0'],\n                                                             eta_min = CONFIG['min_lr'])\n        \n    \n    elif CONFIG['scheduler'] == None:\n        return None\n    \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.978623Z","iopub.execute_input":"2021-12-09T14:58:30.979164Z","iopub.status.idle":"2021-12-09T14:58:30.988388Z","shell.execute_reply.started":"2021-12-09T14:58:30.979128Z","shell.execute_reply":"2021-12-09T14:58:30.98772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's Try Run","metadata":{}},{"cell_type":"code","source":"foldss = CONFIG['n_fold']\n\nfor fold in range(0, foldss):\n\n    print(f\"{y_}===== Fold: {fold} ====={sr_}\")\n    \n    train_loader, valid_loader = prepare_loaders(fold = fold)\n    \n    model = Model(CONFIG['model_name'])\n    model.to(CONFIG['device'])\n    \n    optimizer = AdamW(model.parameters(), lr = CONFIG['learning_rate'], weight_decay = CONFIG['weight_decay'])\n    scheduler = fetch_scheduler(optimizer)\n    \n    model, history = run_training(model,\n                                  optimizer,\n                                  scheduler,\n                                  device = CONFIG['device'],\n                                  num_epochs = CONFIG['epochs'],\n                                  fold = fold)\n    \n    del model, train_loader, valid_loader\n    gc.collect()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:58:30.989547Z","iopub.execute_input":"2021-12-09T14:58:30.989853Z","iopub.status.idle":"2021-12-09T15:58:40.949617Z","shell.execute_reply.started":"2021-12-09T14:58:30.989818Z","shell.execute_reply":"2021-12-09T15:58:40.948611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Over\")","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:58:40.9541Z","iopub.execute_input":"2021-12-09T15:58:40.954327Z","iopub.status.idle":"2021-12-09T15:58:40.958491Z","shell.execute_reply.started":"2021-12-09T15:58:40.954297Z","shell.execute_reply":"2021-12-09T15:58:40.95774Z"},"trusted":true},"execution_count":null,"outputs":[]}]}