{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Here we are treating it as a Classification problem.\n\n## The final score is the probability predicted by the Model.","metadata":{}},{"cell_type":"code","source":"# Importing libraries\n\nimport math\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport re\nimport unidecode\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom imblearn.under_sampling import RandomUnderSampler\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, GRU, Embedding, Bidirectional\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T08:32:58.264021Z","iopub.execute_input":"2021-11-30T08:32:58.264372Z","iopub.status.idle":"2021-11-30T08:33:02.294816Z","shell.execute_reply.started":"2021-11-30T08:32:58.264283Z","shell.execute_reply":"2021-11-30T08:33:02.294068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining constants\n\nvoc_size = 50000\nmax_sequence_length = 200\nembedding_dim = 300\nBatch_size = 32\n\n\n# train_prev_comp_2 = '../input/toxic-comment/jigsaw-unintended-bias-train.csv'\n# train_prev_comp = \"../input/toxic-comment/jigsaw-toxic-comment-train.csv\"\n# test_cur_comp = \"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\n\ntrain = pd.read_csv('../input/ruddit-jigsaw-dataset-combined-cleaned/toxic_train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nEMBEDDING_FILE = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\n\ndef seed_everything():\n    np.random.seed(123)\n    random.seed(123)\n    tf.random.set_seed(123)\n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n    os.environ['PYTHONHASHSEED'] = str(123)\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:02.297109Z","iopub.execute_input":"2021-11-30T08:33:02.297771Z","iopub.status.idle":"2021-11-30T08:33:03.585349Z","shell.execute_reply.started":"2021-11-30T08:33:02.297727Z","shell.execute_reply":"2021-11-30T08:33:03.584572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for cleaning comments\n\ndef clean_data(data):\n    final = []\n    for sent in data:\n        sent = sent.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n        soup = BeautifulSoup(sent, \"html.parser\")\n        sent = soup.get_text(separator=\" \")\n        remove_https = re.sub(r'http\\S+', '', sent)\n        sent = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n        sent = unidecode.unidecode(sent)\n        sent = sent.lower()\n        sent = re.sub(r\"[^a-zA-Z0-9:$-,()%.?!]+\", ' ', sent) \n        sent = re.sub(r\"[:$-,()%.?!]+\", ' ',sent)\n        stoplist = stopwords.words(\"english\")\n        sent = [word for word in word_tokenize(sent) if word not in stoplist]\n        sent = \" \".join(sent)\n        final.append(sent)\n    \n    return final","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.586675Z","iopub.execute_input":"2021-11-30T08:33:03.586959Z","iopub.status.idle":"2021-11-30T08:33:03.595984Z","shell.execute_reply.started":"2021-11-30T08:33:03.586924Z","shell.execute_reply":"2021-11-30T08:33:03.595236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['txt','isOffensive'],axis=1, inplace=True)\ntrain.head()\ndf = train","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.598282Z","iopub.execute_input":"2021-11-30T08:33:03.599112Z","iopub.status.idle":"2021-11-30T08:33:03.623966Z","shell.execute_reply.started":"2021-11-30T08:33:03.599073Z","shell.execute_reply":"2021-11-30T08:33:03.623174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.626045Z","iopub.execute_input":"2021-11-30T08:33:03.626845Z","iopub.status.idle":"2021-11-30T08:33:03.644495Z","shell.execute_reply.started":"2021-11-30T08:33:03.626801Z","shell.execute_reply":"2021-11-30T08:33:03.643328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading train file from previous competition\n\n# df1 = pd.read_csv(train_prev_comp)\n# df2 = pd.read_csv(train_prev_comp_2)\n# df2 = df2[['id', 'comment_text', 'toxic', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']]\n# df2.columns = ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n# df = pd.concat([df1, df2])\n\n# df[\"y\"] = (df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].sum(axis=1) > 0).astype(int)\n# df.drop([\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"], axis=1, inplace = True)\n# df.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.646148Z","iopub.execute_input":"2021-11-30T08:33:03.646491Z","iopub.status.idle":"2021-11-30T08:33:03.651487Z","shell.execute_reply.started":"2021-11-30T08:33:03.646445Z","shell.execute_reply":"2021-11-30T08:33:03.650501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seeing that dataset is imbalanced\n\n# df[\"y\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.653295Z","iopub.execute_input":"2021-11-30T08:33:03.653945Z","iopub.status.idle":"2021-11-30T08:33:03.662495Z","shell.execute_reply.started":"2021-11-30T08:33:03.653895Z","shell.execute_reply":"2021-11-30T08:33:03.661619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Balacing dataset\n\n# X = np.array(df[\"processed\"].values)\n# X = X.reshape(-1,1)\n# y = np.array(df[\"offensiveness_score\"].values)\n# rus = RandomUnderSampler(random_state=0)\n# x, y = rus.fit_resample(X, y)\n\n# x = x.flatten()\n# df = pd.DataFrame()\n# df[\"text\"] = x\n# df[\"target\"] = y\n\n\n# # Now its balanced\n\n# df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.663956Z","iopub.execute_input":"2021-11-30T08:33:03.664246Z","iopub.status.idle":"2021-11-30T08:33:03.672148Z","shell.execute_reply.started":"2021-11-30T08:33:03.664208Z","shell.execute_reply":"2021-11-30T08:33:03.671244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating column clean_text for cleaned comments\n\n#df[\"processed\"] = clean_data(df[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.673623Z","iopub.execute_input":"2021-11-30T08:33:03.67398Z","iopub.status.idle":"2021-11-30T08:33:03.680227Z","shell.execute_reply.started":"2021-11-30T08:33:03.673939Z","shell.execute_reply":"2021-11-30T08:33:03.679204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining keras Model with GRU units\n\nclass GRU_model(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.Embedding = Embedding(voc_size, embedding_dim, weights=[embedding_matrix], input_length = max_sequence_length)\n        self.GRU1 = Bidirectional(GRU(128, return_sequences=True))\n        self.Dropout1 = Dropout(0.25)\n        self.GRU2 = Bidirectional(GRU(64, return_sequences = False))\n        self.Dropout2 = Dropout(0.25)\n        self.Dense1 = Dense(64, activation=\"relu\")\n        self.Dropout3 = Dropout(0.2)\n        self.Dense2 = Dense(1, activation=\"sigmoid\")\n    \n    def call(self, inputs):\n        x = self.Embedding(inputs)\n        x = self.GRU1(x)\n        x = self.Dropout1(x)\n        x = self.GRU2(x)\n        x = self.Dropout2(x)\n        x = self.Dense1(x)\n        x = self.Dropout3(x)\n        x = self.Dense2(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.682184Z","iopub.execute_input":"2021-11-30T08:33:03.682581Z","iopub.status.idle":"2021-11-30T08:33:03.693727Z","shell.execute_reply.started":"2021-11-30T08:33:03.682483Z","shell.execute_reply":"2021-11-30T08:33:03.692823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using early_stopping as callback function \n# It takes the weigths of epoch with the best val_accuracy\n\nearly_stopping = EarlyStopping(patience = 5,restore_best_weights = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.695486Z","iopub.execute_input":"2021-11-30T08:33:03.69591Z","iopub.status.idle":"2021-11-30T08:33:03.702953Z","shell.execute_reply.started":"2021-11-30T08:33:03.695792Z","shell.execute_reply":"2021-11-30T08:33:03.702023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizing the comments from train dataset\n\ntokenizer = Tokenizer(num_words = voc_size)\ntokenizer.fit_on_texts(df[\"processed\"].values)\nX = tokenizer.texts_to_sequences(df[\"processed\"].values)\nX = pad_sequences(X, maxlen = max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:03.704474Z","iopub.execute_input":"2021-11-30T08:33:03.705567Z","iopub.status.idle":"2021-11-30T08:33:15.235414Z","shell.execute_reply.started":"2021-11-30T08:33:03.705525Z","shell.execute_reply":"2021-11-30T08:33:15.234637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tok=text.Tokenizer(num_words=voc_size,lower=True)\n# tok.fit_on_texts(list(df['processed'])+list(test['text']))\n# X_train=tok.texts_to_sequences(X_train)\n# X_test=tok.texts_to_sequences(X_test)\n# x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n# x_test=sequence.pad_sequences(X_test,maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:15.23824Z","iopub.execute_input":"2021-11-30T08:33:15.23867Z","iopub.status.idle":"2021-11-30T08:33:15.242377Z","shell.execute_reply.started":"2021-11-30T08:33:15.23863Z","shell.execute_reply":"2021-11-30T08:33:15.241709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the GloVe vectors in a dictionary:\n\nembeddings_index = {}\nwith open(EMBEDDING_FILE,encoding='utf8') as f:\n    for line in tqdm(f):\n        values = line.rstrip().rsplit(' ')\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:33:15.243443Z","iopub.execute_input":"2021-11-30T08:33:15.244127Z","iopub.status.idle":"2021-11-30T08:37:38.634469Z","shell.execute_reply.started":"2021-11-30T08:33:15.244085Z","shell.execute_reply":"2021-11-30T08:37:38.633694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index\n#prepare embedding matrix\nnum_words = min(voc_size, len(word_index) + 1)\nembedding_matrix = np.zeros((num_words, embedding_dim))\nfor word, i in word_index.items():\n    if i >= voc_size:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:37:38.635714Z","iopub.execute_input":"2021-11-30T08:37:38.636002Z","iopub.status.idle":"2021-11-30T08:37:38.836339Z","shell.execute_reply.started":"2021-11-30T08:37:38.635963Z","shell.execute_reply":"2021-11-30T08:37:38.835562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GRU_model()\nmodel.compile(\n        loss = tf.keras.losses.BinaryCrossentropy(),\n        optimizer = \"Adam\",\n        metrics = [\"mse\"]\n    )\n\nmodel.fit(\n        X, \n        df.offensiveness_score, \n        epochs = 10, \n        validation_split = 0.2,\n        batch_size = Batch_size, \n        callbacks = [early_stopping]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:37:38.837778Z","iopub.execute_input":"2021-11-30T08:37:38.838039Z","iopub.status.idle":"2021-11-30T08:54:21.697043Z","shell.execute_reply.started":"2021-11-30T08:37:38.838004Z","shell.execute_reply":"2021-11-30T08:54:21.696174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading given test dataset \n\n#test = pd.read_csv(test_cur_comp)\n\ntest[\"text\"] = clean_data(test[\"text\"])\nx_test = tokenizer.texts_to_sequences(test[\"text\"].values)\nx_test = pad_sequences(x_test, maxlen = max_sequence_length)\n\npred = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:54:21.698326Z","iopub.execute_input":"2021-11-30T08:54:21.698597Z","iopub.status.idle":"2021-11-30T08:54:34.140313Z","shell.execute_reply.started":"2021-11-30T08:54:21.69856Z","shell.execute_reply":"2021-11-30T08:54:34.139459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making submission file\n\nfinal = pd.DataFrame()\nfinal[\"comment_id\"] = test[\"comment_id\"]\nfinal[\"score\"] = pred\n\nfinal['score'] = final['score'].rank(method='first')\n\nprint(df.shape)\nprint()\n\nfinal.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:54:34.142001Z","iopub.execute_input":"2021-11-30T08:54:34.142264Z","iopub.status.idle":"2021-11-30T08:54:34.177099Z","shell.execute_reply.started":"2021-11-30T08:54:34.142226Z","shell.execute_reply":"2021-11-30T08:54:34.176333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T08:54:34.178433Z","iopub.execute_input":"2021-11-30T08:54:34.178695Z","iopub.status.idle":"2021-11-30T08:54:34.188642Z","shell.execute_reply.started":"2021-11-30T08:54:34.178659Z","shell.execute_reply":"2021-11-30T08:54:34.187537Z"},"trusted":true},"execution_count":null,"outputs":[]}]}