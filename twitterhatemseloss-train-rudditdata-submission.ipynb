{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport re\nimport time\nimport random\nimport string\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport copy\nfrom copy import deepcopy\n\n\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nfrom bs4 import BeautifulSoup\n\nimport nltk\n# from nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom transformers import AutoTokenizer, AutoModel, AdamW\n\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-09T08:05:05.976017Z","iopub.execute_input":"2021-12-09T08:05:05.976513Z","iopub.status.idle":"2021-12-09T08:05:13.788178Z","shell.execute_reply.started":"2021-12-09T08:05:05.976415Z","shell.execute_reply":"2021-12-09T08:05:13.787423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONFIG","metadata":{}},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n#     model_name = '../input/dislike-friends-part3/Hate-speech-CNERG/bert-base-uncased-hatexplain',\n    model_name = '../input/dislike-friends-eng-all/cardiffnlp/twitter-roberta-base-hate',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:13.789958Z","iopub.execute_input":"2021-12-09T08:05:13.790201Z","iopub.status.idle":"2021-12-09T08:05:14.096025Z","shell.execute_reply.started":"2021-12-09T08:05:13.790167Z","shell.execute_reply":"2021-12-09T08:05:14.095319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deteministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.097441Z","iopub.execute_input":"2021-12-09T08:05:14.097689Z","iopub.status.idle":"2021-12-09T08:05:14.106814Z","shell.execute_reply.started":"2021-12-09T08:05:14.097657Z","shell.execute_reply":"2021-12-09T08:05:14.10596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nprint(df.shape)\nprint()\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.109313Z","iopub.execute_input":"2021-12-09T08:05:14.109855Z","iopub.status.idle":"2021-12-09T08:05:14.227622Z","shell.execute_reply.started":"2021-12-09T08:05:14.109817Z","shell.execute_reply":"2021-12-09T08:05:14.226825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# nltk.download('stopwords')\n# STOPWORDS = nltk.corpus.stopwords.words('english')\n# set(STOPWORDS)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.229013Z","iopub.execute_input":"2021-12-09T08:05:14.229555Z","iopub.status.idle":"2021-12-09T08:05:14.233087Z","shell.execute_reply.started":"2021-12-09T08:05:14.229517Z","shell.execute_reply":"2021-12-09T08:05:14.232244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# STOPWORDS = ['a','about', 'above','after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at',\\\n#              'be', 'because', 'been', 'before','being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', 'd', 'did','didn',\"didn't\",\\\n#              'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few','for', 'from', 'further', 'had', 'hadn',\\\n#              \"hadn't\", 'has', 'hasn',\"hasn't\",'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', \\\n#              'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", \\\n#              'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other',\\\n#              'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \\\n#              \"shouldn't\", 'so', 'some', 'such', 't', 'than','that', \"that'll\", 'the', 'their', 'theirs','them','themselves', 'then', 'there', 'these', 'they', \\\n#              'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\",\\\n#              'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', \\\n#              'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \\\n#              \"you're\", \"you've\", 'your', 'yours', 'yourself','yourselves']\n\n# print(len(STOPWORDS))\n# set(STOPWORDS)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.234814Z","iopub.execute_input":"2021-12-09T08:05:14.235624Z","iopub.status.idle":"2021-12-09T08:05:14.243036Z","shell.execute_reply.started":"2021-12-09T08:05:14.235579Z","shell.execute_reply":"2021-12-09T08:05:14.242237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## kesha_mandal's code\n# def washing(comment):\n\n#     comment = re.sub('[^a-zA-Z]', ' ', comment)\n#     comment = comment.lower()\n#     comment = comment.split()\n#     stemmer = SnowballStemmer('english')\n#     lemmatizer = WordNetLemmatizer()\n#     comment = [stemmer.stem(word) for word in comment if not word in set(STOPWORDS)]\n#     comment = [lemmatizer.lemmatize(word) for word in comment]\n#     comment = ' '.join(comment)\n    # corpus.append(comment)\n    # return corpus\n#     return comment\n\n\n\n##  https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-infer/notebook\n# def text_cleaning(text):\n    \n#     template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n#     text = template.sub(r'', text)\n    \n#     soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n#     only_text = soup.get_text()\n#     text = only_text\n    \n#     emoji_pattern = re.compile(\"[\"\n#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n#                                u\"\\U00002702-\\U000027B0\"\n#                                u\"\\U000024C2-\\U0001F251\"\n#                                \"]+\", flags=re.UNICODE)\n#     text = emoji_pattern.sub(r'', text)\n#     text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n#     text = re.sub(' +', ' ', text) #Remove Extra Spaces\n#     text = text.strip() # remove spaces at the beginning and at the end of string\n\n#     return text","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.244846Z","iopub.execute_input":"2021-12-09T08:05:14.245335Z","iopub.status.idle":"2021-12-09T08:05:14.253993Z","shell.execute_reply.started":"2021-12-09T08:05:14.245284Z","shell.execute_reply":"2021-12-09T08:05:14.253233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## https://www.kaggle.com/kishalmandal/most-detailed-eda-tf-idf-and-logistic-reg\n\n# df[\"text\"] = df[\"text\"].str.replace('fk', 'fuck')\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.257104Z","iopub.execute_input":"2021-12-09T08:05:14.257573Z","iopub.status.idle":"2021-12-09T08:05:14.265712Z","shell.execute_reply.started":"2021-12-09T08:05:14.257544Z","shell.execute_reply":"2021-12-09T08:05:14.264986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[\"text\"] = df[\"text\"].apply(text_cleaning)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.267095Z","iopub.execute_input":"2021-12-09T08:05:14.267669Z","iopub.status.idle":"2021-12-09T08:05:14.274342Z","shell.execute_reply.started":"2021-12-09T08:05:14.26763Z","shell.execute_reply":"2021-12-09T08:05:14.273531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[\"text\"] = df[\"text\"].apply(washing)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.278625Z","iopub.execute_input":"2021-12-09T08:05:14.279045Z","iopub.status.idle":"2021-12-09T08:05:14.284233Z","shell.execute_reply.started":"2021-12-09T08:05:14.279015Z","shell.execute_reply":"2021-12-09T08:05:14.283522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Dataset Class","metadata":{}},{"cell_type":"code","source":"class JDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        \n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n#         self.score = df['score']\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(text, truncation = True,\n                                            add_special_tokens = True, \n                                            max_length = self.max_len,\n                                            padding = 'max_length')\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n#         target = self.score[index]\n        \n        return {'ids' : torch.tensor(ids, dtype = torch.long), \n                'mask' : torch.tensor(mask, dtype = torch.long),\n#                 'target' : torch.tensor(target, dtype = torch.float)\n               }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.287428Z","iopub.execute_input":"2021-12-09T08:05:14.287643Z","iopub.status.idle":"2021-12-09T08:05:14.296052Z","shell.execute_reply.started":"2021-12-09T08:05:14.28762Z","shell.execute_reply":"2021-12-09T08:05:14.295234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Dataset, Test DataLoader","metadata":{}},{"cell_type":"code","source":"## Actual TestDataset\ntest_dataset = JDataset(df, CONFIG['tokenizer'], max_length = CONFIG['max_length'])\n\ntest_loader = DataLoader(test_dataset,\n                         batch_size = CONFIG['test_batch_size'],\n                         num_workers = os.cpu_count(),\n                         shuffle = False,\n                         pin_memory = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.297084Z","iopub.execute_input":"2021-12-09T08:05:14.297767Z","iopub.status.idle":"2021-12-09T08:05:14.311261Z","shell.execute_reply.started":"2021-12-09T08:05:14.297725Z","shell.execute_reply":"2021-12-09T08:05:14.310547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(p = 0.2)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, ids, mask):\n        model_out = self.model(input_ids = ids,\n                               attention_mask = mask,\n                               output_hidden_states = False)\n        \n        out = self.dropout(model_out[1])\n        output = self.linear(out)\n        outputs = self.sigmoid(output)\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.312775Z","iopub.execute_input":"2021-12-09T08:05:14.313325Z","iopub.status.idle":"2021-12-09T08:05:14.322023Z","shell.execute_reply.started":"2021-12-09T08:05:14.313269Z","shell.execute_reply":"2021-12-09T08:05:14.321161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Paths","metadata":{}},{"cell_type":"code","source":"## Model paths\nMODEL_PATHS = [\n    '../input/twitterhate-mseloss-train-10epoch-rudditdata/Loss-Fold-0.bin',\n    '../input/twitterhate-mseloss-train-10epoch-rudditdata/Loss-Fold-1.bin',\n    '../input/twitterhate-mseloss-train-10epoch-rudditdata/Loss-Fold-2.bin',\n    '../input/twitterhate-mseloss-train-10epoch-rudditdata/Loss-Fold-3.bin',\n    '../input/twitterhate-mseloss-train-10epoch-rudditdata/Loss-Fold-4.bin'\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.323521Z","iopub.execute_input":"2021-12-09T08:05:14.324105Z","iopub.status.idle":"2021-12-09T08:05:14.332141Z","shell.execute_reply.started":"2021-12-09T08:05:14.324066Z","shell.execute_reply":"2021-12-09T08:05:14.331375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    \n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.\n    PREDS =[]\n    \n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    \n    for step, data in bar:\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n        \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.333621Z","iopub.execute_input":"2021-12-09T08:05:14.334179Z","iopub.status.idle":"2021-12-09T08:05:14.344357Z","shell.execute_reply.started":"2021-12-09T08:05:14.33414Z","shell.execute_reply":"2021-12-09T08:05:14.343639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference Function","metadata":{}},{"cell_type":"code","source":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = Model(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting prediction for model {i + 1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_predss = np.mean(final_preds, axis = 0)\n    return final_predss","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.346061Z","iopub.execute_input":"2021-12-09T08:05:14.346638Z","iopub.status.idle":"2021-12-09T08:05:14.354094Z","shell.execute_reply.started":"2021-12-09T08:05:14.346598Z","shell.execute_reply":"2021-12-09T08:05:14.353276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:05:14.355775Z","iopub.execute_input":"2021-12-09T08:05:14.356258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total Predictiions: {preds.shape[0]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['score'] = preds\n\nprint(df.shape)\nprint()\n\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"df['score'] = df['score'].rank(method='first')\n\nprint(df.shape)\nprint()\n\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('text', axis=1, inplace=True)\n\nprint(df.shape)\nprint()\n\ndf.to_csv(\"submission.csv\", index=False)\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}