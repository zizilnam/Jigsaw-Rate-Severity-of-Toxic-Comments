{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport re\nimport time\nimport random\nimport string\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm\nfrom collections import defaultdict\nimport copy\nfrom copy import deepcopy\n\nimport nltk\n# from nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom transformers import AutoTokenizer, AutoModel, AdamW\n\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-09T12:48:04.334297Z","iopub.execute_input":"2021-12-09T12:48:04.334672Z","iopub.status.idle":"2021-12-09T12:48:13.843711Z","shell.execute_reply.started":"2021-12-09T12:48:04.334562Z","shell.execute_reply":"2021-12-09T12:48:13.842677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# id_generator","metadata":{}},{"cell_type":"code","source":"def id_generator(size = 12, chars = string.ascii_lowercase + string.digits):\n    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n\nHASH_NAME = id_generator(size = 12)\nprint(HASH_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:13.845643Z","iopub.execute_input":"2021-12-09T12:48:13.845976Z","iopub.status.idle":"2021-12-09T12:48:13.855349Z","shell.execute_reply.started":"2021-12-09T12:48:13.84593Z","shell.execute_reply":"2021-12-09T12:48:13.854335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"CONFIG = {\"seed\": 2021,\n          \"epochs\": 10,\n          \"model_name\": \"cardiffnlp/twitter-roberta-base-hate\",\n#           \"model_name\": \"roberta-base\",\n          \"train_batch_size\": 32,\n          \"valid_batch_size\": 64,\n          \"max_length\": 128,\n          \"learning_rate\": 1e-4,\n          \"scheduler\": 'CosineAnnealingLR',\n          \"min_lr\": 1e-6,\n          \"T_max\": 500,\n          \"weight_decay\": 1e-6,\n          \"n_fold\": 5,\n          \"n_accumulate\": 1,\n          \"num_classes\": 1,\n          \"margin\": 0.5,\n          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n          \"hash_name\": HASH_NAME\n          }\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nCONFIG['group'] = f'{HASH_NAME}-Baseline'","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:13.856878Z","iopub.execute_input":"2021-12-09T12:48:13.857876Z","iopub.status.idle":"2021-12-09T12:48:20.188905Z","shell.execute_reply.started":"2021-12-09T12:48:13.857826Z","shell.execute_reply":"2021-12-09T12:48:20.187939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deteministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.191745Z","iopub.execute_input":"2021-12-09T12:48:20.192067Z","iopub.status.idle":"2021-12-09T12:48:20.201766Z","shell.execute_reply.started":"2021-12-09T12:48:20.192023Z","shell.execute_reply":"2021-12-09T12:48:20.200736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')\nprint(df.shape)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.204957Z","iopub.execute_input":"2021-12-09T12:48:20.205243Z","iopub.status.idle":"2021-12-09T12:48:20.308625Z","shell.execute_reply.started":"2021-12-09T12:48:20.205203Z","shell.execute_reply":"2021-12-09T12:48:20.30757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Give more weight to severe toxic \n# df['severe_toxic'] = df.severe_toxic * 10\n# df['toxic'] = df.toxic * 6 \n# df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\n# df['y'] = df['y']/df['y'].max()\n\n# df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n# df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.310615Z","iopub.execute_input":"2021-12-09T12:48:20.311161Z","iopub.status.idle":"2021-12-09T12:48:20.316676Z","shell.execute_reply.started":"2021-12-09T12:48:20.311103Z","shell.execute_reply":"2021-12-09T12:48:20.315271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\ndf = df[['txt', 'offensiveness_score']]\ndf.columns = ['text', 'score']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.318694Z","iopub.execute_input":"2021-12-09T12:48:20.319068Z","iopub.status.idle":"2021-12-09T12:48:20.349598Z","shell.execute_reply.started":"2021-12-09T12:48:20.319001Z","shell.execute_reply":"2021-12-09T12:48:20.348607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.score.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.351203Z","iopub.execute_input":"2021-12-09T12:48:20.351787Z","iopub.status.idle":"2021-12-09T12:48:20.370007Z","shell.execute_reply.started":"2021-12-09T12:48:20.351735Z","shell.execute_reply":"2021-12-09T12:48:20.368741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n\n# df1 = pd.read_csv('../input/ruddit-jigsaw-dataset-combined-cleaned/toxic_train.csv')\n# df1 = df1[['txt', 'offensiveness_score']]\n# df1.columns = ['text', 'score']\n# print(df1.shape)\n# df1.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.372094Z","iopub.execute_input":"2021-12-09T12:48:20.372827Z","iopub.status.idle":"2021-12-09T12:48:20.378289Z","shell.execute_reply.started":"2021-12-09T12:48:20.372777Z","shell.execute_reply":"2021-12-09T12:48:20.37685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from copy import deepcopy\n# print(df1.loc[df1.score!=0.0].shape)\n# df2 = deepcopy(df1.loc[df1.score!=0.0])\n# df2.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.384444Z","iopub.execute_input":"2021-12-09T12:48:20.384889Z","iopub.status.idle":"2021-12-09T12:48:20.389711Z","shell.execute_reply.started":"2021-12-09T12:48:20.384809Z","shell.execute_reply":"2021-12-09T12:48:20.3884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from copy import deepcopy\n# df3 = deepcopy(df1.loc[df1.score == 0])\n# print(df3.shape)\n# df3.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.391753Z","iopub.execute_input":"2021-12-09T12:48:20.392355Z","iopub.status.idle":"2021-12-09T12:48:20.401594Z","shell.execute_reply.started":"2021-12-09T12:48:20.392304Z","shell.execute_reply":"2021-12-09T12:48:20.400472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.concat([df, df2],axis = 0)\n# df = df.reset_index(drop=True)\n# print(df.shape)\n# df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.405435Z","iopub.execute_input":"2021-12-09T12:48:20.405722Z","iopub.status.idle":"2021-12-09T12:48:20.412692Z","shell.execute_reply.started":"2021-12-09T12:48:20.405675Z","shell.execute_reply":"2021-12-09T12:48:20.411773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# nltk.download('stopwords')\n# STOPWORDS = nltk.corpus.stopwords.words('english')\n\n# ## kesha_mandal's code\n# def washing(comment):\n\n#     comment = re.sub('[^a-zA-Z]', ' ', comment)\n#     comment = comment.lower()\n#     comment = comment.split()\n#     stemmer = SnowballStemmer('english')\n#     lemmatizer = WordNetLemmatizer()\n#     comment = [stemmer.stem(word) for word in comment if not word in set(STOPWORDS)]\n#     comment = [lemmatizer.lemmatize(word) for word in comment]\n#     comment = ' '.join(comment)\n#     # corpus.append(comment)\n#     # return corpus\n#     return comment\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.414387Z","iopub.execute_input":"2021-12-09T12:48:20.415125Z","iopub.status.idle":"2021-12-09T12:48:20.424852Z","shell.execute_reply.started":"2021-12-09T12:48:20.415077Z","shell.execute_reply":"2021-12-09T12:48:20.423723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##  https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-infer/notebook\n# def text_cleaning(text):\n    \n#     template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n#     text = template.sub(r'', text)\n    \n#     soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n#     only_text = soup.get_text()\n#     text = only_text\n    \n#     emoji_pattern = re.compile(\"[\"\n#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n#                                u\"\\U00002702-\\U000027B0\"\n#                                u\"\\U000024C2-\\U0001F251\"\n#                                \"]+\", flags=re.UNICODE)\n#     text = emoji_pattern.sub(r'', text)\n    \n#     text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n#     text = re.sub(' +', ' ', text) #Remove Extra Spaces\n#     text = text.strip() # remove spaces at the beginning and at the end of string\n\n#     return text","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.42697Z","iopub.execute_input":"2021-12-09T12:48:20.427364Z","iopub.status.idle":"2021-12-09T12:48:20.44214Z","shell.execute_reply.started":"2021-12-09T12:48:20.427314Z","shell.execute_reply":"2021-12-09T12:48:20.441005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## https://www.kaggle.com/kishalmandal/most-detailed-eda-tf-idf-and-logistic-reg\n\n# df[\"less_toxic\"] = df[\"less_toxic\"].str.replace('fk', 'fuck')\n# df[\"less_toxic\"] = df[\"less_toxic\"].str.replace('fuk', 'fuck')\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.444707Z","iopub.execute_input":"2021-12-09T12:48:20.445982Z","iopub.status.idle":"2021-12-09T12:48:20.453427Z","shell.execute_reply.started":"2021-12-09T12:48:20.445931Z","shell.execute_reply":"2021-12-09T12:48:20.452256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['less_toxic'] = df['less_toxic'].apply(text_cleaning)\n# df['more_toxic'] = df['more_toxic'].apply(text_cleaning)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.457283Z","iopub.execute_input":"2021-12-09T12:48:20.457553Z","iopub.status.idle":"2021-12-09T12:48:20.465307Z","shell.execute_reply.started":"2021-12-09T12:48:20.45752Z","shell.execute_reply":"2021-12-09T12:48:20.464267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['less_toxic'] = df['less_toxic'].apply(washing)\n# df['more_toxic'] = df['more_toxic'].apply(washing)\n\n# df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.467015Z","iopub.execute_input":"2021-12-09T12:48:20.467859Z","iopub.status.idle":"2021-12-09T12:48:20.480268Z","shell.execute_reply.started":"2021-12-09T12:48:20.46781Z","shell.execute_reply":"2021-12-09T12:48:20.479246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFold","metadata":{}},{"cell_type":"code","source":"k = CONFIG['n_fold']\nskf = KFold(n_splits = k, shuffle = True, random_state = CONFIG['seed'])\nfor fold, (k, v) in enumerate(skf.split(X = df)):\n    df.loc[v, 'kfold'] = int(fold)\n\ndf['kfold'] = df['kfold'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.482092Z","iopub.execute_input":"2021-12-09T12:48:20.48274Z","iopub.status.idle":"2021-12-09T12:48:20.509297Z","shell.execute_reply.started":"2021-12-09T12:48:20.48268Z","shell.execute_reply":"2021-12-09T12:48:20.508354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class JDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        \n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        self.score = df['score']\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(text, truncation = True,\n                                            add_special_tokens = True, \n                                            max_length = self.max_len,\n                                            padding = 'max_length')\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        target = self.score[index]\n        \n        return {'ids' : torch.tensor(ids, dtype = torch.long), \n                'mask' : torch.tensor(mask, dtype = torch.long),\n                'target' : torch.tensor(target, dtype = torch.float)\n               }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.512356Z","iopub.execute_input":"2021-12-09T12:48:20.512697Z","iopub.status.idle":"2021-12-09T12:48:20.522186Z","shell.execute_reply.started":"2021-12-09T12:48:20.512632Z","shell.execute_reply":"2021-12-09T12:48:20.520915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepare_loader Function","metadata":{}},{"cell_type":"code","source":"def prepare_loaders(fold):\n    \n    df_train = df[df.kfold != fold].reset_index(drop = True)\n    df_valid = df[df.kfold == fold].reset_index(drop = True)\n    \n    train_dataset = JDataset(df_train, tokenizer = CONFIG['tokenizer'], max_length = CONFIG['max_length'])\n    valid_dataset = JDataset(df_valid, tokenizer = CONFIG['tokenizer'], max_length = CONFIG['max_length'])\n    \n    train_loader = DataLoader(train_dataset, \n                              batch_size = CONFIG['train_batch_size'],\n                              num_workers = os.cpu_count(),\n                              shuffle = True, \n                              pin_memory = True,\n                              drop_last = True)\n    \n    valid_loader = DataLoader(valid_dataset, \n                              batch_size = CONFIG['train_batch_size'],\n                              num_workers = os.cpu_count(),\n                              shuffle = False,\n                              pin_memory = True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.524284Z","iopub.execute_input":"2021-12-09T12:48:20.525031Z","iopub.status.idle":"2021-12-09T12:48:20.536169Z","shell.execute_reply.started":"2021-12-09T12:48:20.524981Z","shell.execute_reply":"2021-12-09T12:48:20.534999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(p = 0.2)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n#         self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, ids, mask):\n        model_out = self.model(input_ids = ids,\n                               attention_mask = mask,\n                               output_hidden_states = False)\n        \n        out = self.dropout(model_out[1])\n        output = self.linear(out)\n#         outputs = self.sigmoid(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.538112Z","iopub.execute_input":"2021-12-09T12:48:20.538679Z","iopub.status.idle":"2021-12-09T12:48:20.551575Z","shell.execute_reply.started":"2021-12-09T12:48:20.53861Z","shell.execute_reply":"2021-12-09T12:48:20.550569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n# loss_fn = nn.BCELoss()\n# loss_fn= nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.554699Z","iopub.execute_input":"2021-12-09T12:48:20.554991Z","iopub.status.idle":"2021-12-09T12:48:20.563321Z","shell.execute_reply.started":"2021-12-09T12:48:20.554959Z","shell.execute_reply":"2021-12-09T12:48:20.562346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train one Epoch Function","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    \n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.\n    \n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    \n    for step, data in bar:\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        targets = data['target'].to(device, dtype = torch.float)\n        targets= targets.reshape(-1, 1)\n        \n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask)\n        \n        loss = loss_fn(outputs, targets)\n        loss = loss / CONFIG['n_accumulate']\n        loss.backward()\n        \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.567129Z","iopub.execute_input":"2021-12-09T12:48:20.567759Z","iopub.status.idle":"2021-12-09T12:48:20.580062Z","shell.execute_reply.started":"2021-12-09T12:48:20.567693Z","shell.execute_reply":"2021-12-09T12:48:20.578958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    \n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.\n    \n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    \n    for step, data in bar:\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        targets = data['target'].to(device, dtype = torch.float)\n        targets= targets.reshape(-1, 1)\n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask)\n#         outputs\n        loss = loss_fn(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.581677Z","iopub.execute_input":"2021-12-09T12:48:20.582321Z","iopub.status.idle":"2021-12-09T12:48:20.5974Z","shell.execute_reply.started":"2021-12-09T12:48:20.582274Z","shell.execute_reply":"2021-12-09T12:48:20.596466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Training Function","metadata":{}},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n    \n    if torch.cuda.is_available():\n        print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n        print()\n        \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_loss = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader = train_loader, device = CONFIG['device'], epoch = epoch)\n        valid_epoch_loss = valid_one_epoch(model, dataloader = valid_loader, device = CONFIG['device'], epoch = epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        \n        if valid_epoch_loss <= best_epoch_loss:\n            print(f\"{b_} Validation Loss Improved: [{best_epoch_loss} ---> {valid_epoch_loss}]\")\n            best_epoch_loss = valid_epoch_loss\n#             run.summary['Best Loss'] = best_epoch_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f\"Loss-Fold-{fold}.bin\"\n            torch.save(model.state_dict(), PATH)\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n        \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.599025Z","iopub.execute_input":"2021-12-09T12:48:20.599275Z","iopub.status.idle":"2021-12-09T12:48:20.616026Z","shell.execute_reply.started":"2021-12-09T12:48:20.599245Z","shell.execute_reply":"2021-12-09T12:48:20.614776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fetch_scheduler function","metadata":{}},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, \n                                                   T_max = CONFIG['T_max'],\n                                                   eta_min = CONFIG['min_lr'])\n        \n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n                                                             T_0 = CONFIG['T_0'],\n                                                             eta_min = CONFIG['min_lr'])\n        \n    \n    elif CONFIG['scheduler'] == None:\n        return None\n    \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.618003Z","iopub.execute_input":"2021-12-09T12:48:20.618345Z","iopub.status.idle":"2021-12-09T12:48:20.632383Z","shell.execute_reply.started":"2021-12-09T12:48:20.618299Z","shell.execute_reply":"2021-12-09T12:48:20.631432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's Try Run","metadata":{}},{"cell_type":"code","source":"foldss = CONFIG['n_fold']\n\nfor fold in range(0, foldss):\n\n    print(f\"{y_}===== Fold: {fold} ====={sr_}\")\n    \n    train_loader, valid_loader = prepare_loaders(fold = fold)\n    \n    model = Model(CONFIG['model_name'])\n    model.to(CONFIG['device'])\n    \n    optimizer = AdamW(model.parameters(), lr = CONFIG['learning_rate'], weight_decay = CONFIG['weight_decay'])\n    scheduler = fetch_scheduler(optimizer)\n    \n    model, history = run_training(model,\n                                  optimizer,\n                                  scheduler,\n                                  device = CONFIG['device'],\n                                  num_epochs = CONFIG['epochs'],\n                                  fold = fold)\n    \n    del model, train_loader, valid_loader\n    gc.collect()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:48:20.634474Z","iopub.execute_input":"2021-12-09T12:48:20.63486Z","iopub.status.idle":"2021-12-09T13:54:59.624059Z","shell.execute_reply.started":"2021-12-09T12:48:20.634813Z","shell.execute_reply":"2021-12-09T13:54:59.622921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Over\")","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:54:59.629457Z","iopub.execute_input":"2021-12-09T13:54:59.629873Z","iopub.status.idle":"2021-12-09T13:54:59.637403Z","shell.execute_reply.started":"2021-12-09T13:54:59.629838Z","shell.execute_reply":"2021-12-09T13:54:59.636354Z"},"trusted":true},"execution_count":null,"outputs":[]}]}